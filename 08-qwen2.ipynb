{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install qwen-vl-utils"
      ],
      "metadata": {
        "id": "oiopm5Eh2upW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJ5w1zJG2oiY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# maybe requires '4.51.3' +\n",
        "from transformers import AutoProcessor, AutoModel, AutoConfig, Qwen2VLForConditionalGeneration\n",
        "from transformers.models.qwen2_vl.modeling_qwen2_vl import Qwen2VisionTransformerPretrainedModel\n",
        "\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "from safetensors.torch import load_file\n",
        "from qwen_vl_utils import process_vision_info"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print('Using device: {0}'.format(device))"
      ],
      "metadata": {
        "id": "HE4_nCIA28v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reduce memory usage\n",
        "min_pixels = 256*28*28\n",
        "max_pixels = 1280*28*28"
      ],
      "metadata": {
        "id": "qBgMN3Mx2-7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = AutoConfig.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n",
        "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n",
        "model = Qwen2VisionTransformerPretrainedModel.from_pretrained('jeddobson/qwen2-vl-2b-instruct-vision')\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "0Hbb8LoX3BSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained = Qwen2VLForConditionalGeneration.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n",
        "pretrained.to(device)"
      ],
      "metadata": {
        "id": "lCLPSAHZ5lw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_prompt(image, prompt=\"\", min_pixels = min_pixels, max_pixels = max_pixels):\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"image\",\n",
        "                    \"image\": image,\n",
        "                    \"max_pixels\": max_pixels,\n",
        "                    \"min_pixels\": min_pixels,\n",
        "                },\n",
        "                {\"type\": \"text\", \"text\": prompt},\n",
        "            ],\n",
        "        }\n",
        "    ]\n",
        "    return messages"
      ],
      "metadata": {
        "id": "fZF1Quv83m7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(image):\n",
        "    text = processor.apply_chat_template(format_prompt(image,prompt=\"Describe this image\"), tokenize=False, add_generation_prompt=True)\n",
        "    image_inputs, video_inputs = process_vision_info(format_prompt(image))\n",
        "    inputs = processor(\n",
        "        text=[text],\n",
        "        images=image_inputs,\n",
        "        videos=video_inputs,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\")\n",
        "    inputs = inputs.to(device)\n",
        "    pixel_values = inputs[\"pixel_values\"].type(torch.bfloat16)\n",
        "    with torch.no_grad():\n",
        "        image_embeds = model(pixel_values, grid_thw=inputs[\"image_grid_thw\"])\n",
        "    return image_embeds.mean(dim=0)"
      ],
      "metadata": {
        "id": "hnyXuiXm3pkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = 'https://collections.dartmouth.edu/xcdas-derivative/college-photographer/jpeg-1k/college-photographer-2006-1807375212.jpg?disposition=download'"
      ],
      "metadata": {
        "id": "OIJm73WL6JfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embs = get_embedding(img)"
      ],
      "metadata": {
        "id": "ae7gUNU24WUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embs.shape"
      ],
      "metadata": {
        "id": "4MRYIfwl6fW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(image):\n",
        "    text = processor.apply_chat_template(format_prompt(image,prompt=\"Describe this image\"), tokenize=False, add_generation_prompt=True)\n",
        "    image_inputs, video_inputs = process_vision_info(format_prompt(image))\n",
        "    inputs = processor(\n",
        "        text=[text],\n",
        "        images=image_inputs,\n",
        "        videos=video_inputs,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\")\n",
        "    inputs = inputs.to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = pretrained.generate(**inputs, max_new_tokens=256)\n",
        "    generated_ids_trimmed = [\n",
        "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, outputs)\n",
        "    ]\n",
        "    response = processor.batch_decode(generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "    return response"
      ],
      "metadata": {
        "id": "bhYmCxD25J0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_response(img)"
      ],
      "metadata": {
        "id": "zD2elTud6LSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Image.open(requests.get(img, stream=True).raw))"
      ],
      "metadata": {
        "id": "wsQbjgPQ9XzW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}