{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oiopm5Eh2upW"
   },
   "outputs": [],
   "source": [
    "!pip install qwen-vl-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJ5w1zJG2oiY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# maybe requires '4.51.3' +\n",
    "from transformers import AutoProcessor, AutoModel, AutoConfig, Qwen2VLForConditionalGeneration\n",
    "from transformers.models.qwen2_vl.modeling_qwen2_vl import Qwen2VisionTransformerPretrainedModel\n",
    "\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "from safetensors.torch import load_file\n",
    "from qwen_vl_utils import process_vision_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HE4_nCIA28v4"
   },
   "outputs": [],
   "source": [
    "if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('Using device: {0}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBgMN3Mx2-7O"
   },
   "outputs": [],
   "source": [
    "# reduce memory usage\n",
    "min_pixels = 256*28*28\n",
    "max_pixels = 1280*28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Hbb8LoX3BSW"
   },
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n",
    "model = Qwen2VisionTransformerPretrainedModel.from_pretrained('jeddobson/qwen2-vl-2b-instruct-vision')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lCLPSAHZ5lw6"
   },
   "outputs": [],
   "source": [
    "pretrained = Qwen2VLForConditionalGeneration.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n",
    "pretrained.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZF1Quv83m7s"
   },
   "outputs": [],
   "source": [
    "def format_prompt(image, prompt=\"\", min_pixels = min_pixels, max_pixels = max_pixels):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": image,\n",
    "                    \"max_pixels\": max_pixels,\n",
    "                    \"min_pixels\": min_pixels,\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hnyXuiXm3pkr"
   },
   "outputs": [],
   "source": [
    "def get_embedding(image):\n",
    "    text = processor.apply_chat_template(format_prompt(image,prompt=\"Describe this image\"), tokenize=False, add_generation_prompt=True)\n",
    "    image_inputs, video_inputs = process_vision_info(format_prompt(image))\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\")\n",
    "    inputs = inputs.to(device)\n",
    "    pixel_values = inputs[\"pixel_values\"].type(torch.bfloat16)\n",
    "    with torch.no_grad():\n",
    "        image_embeds = model(pixel_values, grid_thw=inputs[\"image_grid_thw\"])\n",
    "    return image_embeds.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OIJm73WL6JfB"
   },
   "outputs": [],
   "source": [
    "img = 'https://collections.dartmouth.edu/xcdas-derivative/college-photographer/jpeg-1k/college-photographer-2006-1807375212.jpg?disposition=download'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ae7gUNU24WUN"
   },
   "outputs": [],
   "source": [
    "embs = get_embedding(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4MRYIfwl6fW1"
   },
   "outputs": [],
   "source": [
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bhYmCxD25J0A"
   },
   "outputs": [],
   "source": [
    "def get_response(image,prompt=\"Describe this image\"):\n",
    "    text = processor.apply_chat_template(format_prompt(image,prompt=prompt), tokenize=False, add_generation_prompt=True)\n",
    "    image_inputs, video_inputs = process_vision_info(format_prompt(image))\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\")\n",
    "    inputs = inputs.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = pretrained.generate(**inputs, max_new_tokens=256)\n",
    "    generated_ids_trimmed = [\n",
    "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, outputs)\n",
    "    ]\n",
    "    response = processor.batch_decode(generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zD2elTud6LSW"
   },
   "outputs": [],
   "source": [
    "get_response(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wsQbjgPQ9XzW"
   },
   "outputs": [],
   "source": [
    "display(Image.open(requests.get(img, stream=True).raw))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
